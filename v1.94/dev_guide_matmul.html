<!-- HTML header for doxygen 1.8.5-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.5"/>
<title>oneDNN: Matrix Multiplication</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<script src="assets/mathjax/MathJax.js?config=TeX-AMS_CHTML,dnnl"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Montserrat" rel="stylesheet">
<link href="assets/customdoxygen.css" rel="stylesheet" type="text/css" />
<script type="text/javascript" src="assets/dnn.js"></script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
   <div id="projectname">oneAPI Deep Neural Network Library (oneDNN)
   &#160;<span id="projectnumber">1.94.0</span>
   </div>
   <div id="projectbrief">Performance library for Deep Learning</div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.5 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="modules.html"><span>Modules</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li><a href="examples.html"><span>Examples</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Namespaces</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(6)"><span class="SelectionMark">&#160;</span>Typedefs</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(7)"><span class="SelectionMark">&#160;</span>Enumerations</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(8)"><span class="SelectionMark">&#160;</span>Enumerator</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(9)"><span class="SelectionMark">&#160;</span>Groups</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(10)"><span class="SelectionMark">&#160;</span>Pages</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Matrix Multiplication </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><blockquote class="doxtable">
<p></p>
<p><a class="el" href="group__dnnl__api__matmul.html">API Reference</a></p>
<p></p>
</blockquote>
<p>The matrix multiplication (MatMul) primitive computes the product of two 2D tensors with optional bias addition (the variable names follow the standard <a class="el" href="dev_guide_conventions.html">Naming Conventions</a>):</p>
<p class="formulaDsp">
\[ \dst(m, n) = \sum_{k=0}^{K} \left( \src(m, k) \cdot \weights(k, n) \right) + \bias(m, n) \]
</p>
<p>The MatMul primitive also supports batching multiple independent matrix multiplication operations, in which case the tensors must be 3D:</p>
<p class="formulaDsp">
\[ \dst(mb, m, n) = \sum_{k=0}^{K} \left( \src(mb, m, k) \cdot \weights(mb, k, n) \right) + \bias(mb, m, n) \]
</p>
<p>The bias tensor is optional and supports implicit broadcast semantics: any of its dimensions can be 1 and the same value would be used across the corresponding dimension. However, \(\bias\) must have the same number of dimensions as the \(\dst\).</p>
<h2>Execution Arguments</h2>
<p>When executed, the inputs and outputs should be mapped to an execution argument index as specified by the following table. </p>
<table class="doxtable">
<tr>
<th>Primitive input/output </th><th>Execution argument index  </th></tr>
<tr>
<td>\(\src\) </td><td>DNNL_ARG_SRC </td></tr>
<tr>
<td>\(\weights\) </td><td>DNNL_ARG_WEIGHTS </td></tr>
<tr>
<td>\(\bias\) </td><td>DNNL_ARG_BIAS </td></tr>
<tr>
<td>\(\dst\) </td><td>DNNL_ARG_DST </td></tr>
</table>
<h2>Implementation Details</h2>
<h3>General Notes</h3>
<ol type="1">
<li><p class="startli">The MatMul primitive supports input and output tensors with run-time specified shapes and memory formats. The run-time specified dimensions or strides are specified using the <a class="el" href="group__dnnl__api__memory.html#gaa596c5a6102df77a550bad98f0d5cc12" title="A wildcard value for dimensions that are unknown at a primitive creation time. ">DNNL_RUNTIME_DIM_VAL</a> wildcard value during the primitive initialization and creation stage. At the execution stage, the user must pass fully specified memory objects so that the primitive is able to perform the computations. Note that the less information about shapes or format is available at the creation stage, the less performant execution will be. In particular, if the shape is not known at creation stage, one cannot use the special format tag <a class="el" href="structdnnl_1_1memory.html#a8e71077ed6a5f7fb7b3e6e1a5a2ecf3fa100b8cad7cf2a56f6df78f171f97a1ec" title="Placeholder memory format tag. ">dnnl::memory::format_tag::any</a> to enable an implementation to choose the most appropriate memory format for the corresponding input or output shapes. On the other hand, run-time specified shapes enable users to create a primitive once and use it in different situations.</p>
<dl class="section see"><dt>See Also</dt><dd>Please check tutorials below to see <a class="el" href="group__dnnl__api__memory.html#gaa596c5a6102df77a550bad98f0d5cc12" title="A wildcard value for dimensions that are unknown at a primitive creation time. ">DNNL_RUNTIME_DIM_VAL</a> support in use.</dd></dl>
<h3>Data Types</h3>
</li>
</ol>
<p>The MatMul primitive supports the following combinations of data types for source, destination, weights, and bias tensors:</p>
<table class="doxtable">
<tr>
<th align="left">Source </th><th align="left">Weights </th><th align="left">Destination </th><th align="left">Bias  </th></tr>
<tr>
<td align="left">f32 </td><td align="left">f32 </td><td align="left">f32 </td><td align="left">f32 </td></tr>
<tr>
<td align="left">f16 </td><td align="left">f16 </td><td align="left">f16 </td><td align="left">f16 </td></tr>
<tr>
<td align="left">bf16 </td><td align="left">bf16 </td><td align="left">bf16 </td><td align="left">bf16, f32 </td></tr>
<tr>
<td align="left">u8, s8 </td><td align="left">s8, u8 </td><td align="left">u8, s8, s32, f32 </td><td align="left">u8, s8, s32, f32 </td></tr>
</table>
<h3>Data Representation</h3>
<p>The MatMul primitive expects the following tensors:</p>
<table class="doxtable">
<tr>
<th align="left">Dims </th><th align="left">Source </th><th align="left">Weights </th><th align="left">Destination </th><th align="left">Bias  </th></tr>
<tr>
<td align="left">2D </td><td align="left">\(M \times K\) </td><td align="left">\(K \times N\) </td><td align="left">\(M \times N\) </td><td align="left">None or \((M \text{ or } 1) \times (N \text{ or } 1)\) </td></tr>
<tr>
<td align="left">3D </td><td align="left">\(MB \times M \times K\) </td><td align="left">\(MB \times K \times N\) </td><td align="left">\(MB \times M \times N\) </td><td align="left">None or \((MB \text{ or } 1) \times (M \text{ or } 1) \times (N \text{ or } 1)\) </td></tr>
</table>
<p>The MatMul primitive is generally optimized for the case in which memory objects use plain memory formats (with some restrictions; see the table below). However, it is recommended to use the placeholder memory format <a class="el" href="structdnnl_1_1memory.html#a8e71077ed6a5f7fb7b3e6e1a5a2ecf3fa100b8cad7cf2a56f6df78f171f97a1ec" title="Placeholder memory format tag. ">dnnl::memory::format_tag::any</a> if an input tensor is reused across multiple executions. In this case, the primitive will set the most appropriate memory format for the corresponding input tensor.</p>
<p>The table below shows the combinations of memory formats for which the MatMul primitive is optimized. The memory format of the destination tensor should always be <a class="el" href="structdnnl_1_1memory.html#a8e71077ed6a5f7fb7b3e6e1a5a2ecf3fa187ef4436122d1cc2f40dc2b92f0eba0" title="plain 2D tensor ">dnnl::memory::format_tag::ab</a> for the 2D case and <a class="el" href="structdnnl_1_1memory.html#a8e71077ed6a5f7fb7b3e6e1a5a2ecf3fa900150983cd24fb0d6963f7d28e17f72" title="plain 3D tensor ">dnnl::memory::format_tag::abc</a> for the 3D one.</p>
<table class="doxtable">
<tr>
<th align="left">Dims </th><th align="left">Logical tensors </th><th align="left">MatMul is optimized for the following memory formats  </th></tr>
<tr>
<td align="left">2D </td><td align="left">Source: \(M \times K\) <br/>
 Weights: \(K \times N\) </td><td align="left">Source: <a class="el" href="group__dnnl__api__memory.html#gga395e42b594683adb25ed2d842bb3091da1bd907fc29344dfe7ba88336960dcf53" title="plain 2D tensor ">dnnl_ab</a> or <a class="el" href="group__dnnl__api__memory.html#gga395e42b594683adb25ed2d842bb3091da6a6dbc0b30468d92e32a9cb3f6615c43" title="permuted 2D tensor ">dnnl_ba</a> <br/>
 Weights: <a class="el" href="group__dnnl__api__memory.html#gga395e42b594683adb25ed2d842bb3091da1bd907fc29344dfe7ba88336960dcf53" title="plain 2D tensor ">dnnl_ab</a> or <a class="el" href="group__dnnl__api__memory.html#gga395e42b594683adb25ed2d842bb3091da6a6dbc0b30468d92e32a9cb3f6615c43" title="permuted 2D tensor ">dnnl_ba</a> </td></tr>
<tr>
<td align="left">3D </td><td align="left">Source: \(MB \times M \times K\) <br/>
 Weights: \(MB \times K \times N\) </td><td align="left">Source: <a class="el" href="group__dnnl__api__memory.html#gga395e42b594683adb25ed2d842bb3091dadff5ea69392d7e4da23179dc0ba7cbc2" title="plain 3D tensor ">dnnl_abc</a> or <a class="el" href="group__dnnl__api__memory.html#gga395e42b594683adb25ed2d842bb3091daf8537ed269eb5d0586456db114039c00" title="permuted 3D tensor ">dnnl_acb</a> <br/>
 Weights: <a class="el" href="group__dnnl__api__memory.html#gga395e42b594683adb25ed2d842bb3091dadff5ea69392d7e4da23179dc0ba7cbc2" title="plain 3D tensor ">dnnl_abc</a> or <a class="el" href="group__dnnl__api__memory.html#gga395e42b594683adb25ed2d842bb3091daf8537ed269eb5d0586456db114039c00" title="permuted 3D tensor ">dnnl_acb</a> </td></tr>
</table>
<h3>Attributes and Post-ops</h3>
<p>Attributes and post-ops enable modifying the behavior of the MatMul primitive. The following attributes and post-ops are supported:</p>
<table class="doxtable">
<tr>
<th align="left">Type </th><th align="left">Operation </th><th align="left">Description </th><th align="left">Restrictions  </th></tr>
<tr>
<td align="left">Attribute </td><td align="left"><a class="el" href="structdnnl_1_1primitive__attr.html#a4b81acc8e48886313154f75c1708ae02">Output scales</a> </td><td align="left">Scales the result by given scale factor(s) </td><td align="left"></td></tr>
<tr>
<td align="left">Attribute </td><td align="left"><a class="el" href="structdnnl_1_1primitive__attr.html#aee82deb014cf9702ceb3e725156c25a1">Zero points</a> </td><td align="left">Sets zero point(s) for the corresponding tensors </td><td align="left">Int8 computations only </td></tr>
<tr>
<td align="left">Post-op </td><td align="left"><a class="el" href="structdnnl_1_1post__ops.html#a66606f08467b19091e696b52a2f789e6">Eltwise</a> </td><td align="left">Applies an <a class="el" href="group__dnnl__api__eltwise.html">Eltwise</a> operation to the result </td><td align="left"></td></tr>
<tr>
<td align="left">Post-op </td><td align="left"><a class="el" href="structdnnl_1_1post__ops.html#a078ab8ec15423d2b3d26f3619a78ca38">Sum</a> </td><td align="left">Adds the operation result to the destination tensor instead of overwriting it </td><td align="left"></td></tr>
</table>
<p>To facilitate dynamic quantization, the primitive supports run-time output scales. That means a user could configure attributes with output scales set to the <a class="el" href="group__dnnl__api__memory.html#gab16365c11b4dc88fbb453edb51f1979f" title="A wildcard value for floating point values that are unknown at a primitive creation time...">DNNL_RUNTIME_F32_VAL</a> wildcard value instead of the actual scales, if the scales are not known at the primitive descriptor creation stage. In this case, the user must provide the scales as an additional input memory object with argument <code>DNNL_ARG_ATTR_OUTPUT_SCALES</code> during the execution stage.</p>
<p>Similarly to run-time output scales, the primitive supports run-time zero points. The wildcard value for zero points is <a class="el" href="group__dnnl__api__memory.html#ga30139d5110e9e895ccd93fe503ca4c35" title="A wildcard value for int32_t values that are unknown at a primitive creation time. ">DNNL_RUNTIME_S32_VAL</a>. During the execution stage, the corresponding memory object needs to be passed in the argument with index set to (<code>DNNL_ARG_ATTR_ZERO_POINTS | DNNL_ARG_${MEMORY_INDEX}</code>).</p>
<ul>
<li>For instance, source tensor zero points memory argument would be passed with index (<code>DNNL_ARG_ATTR_ZERO_POINTS | DNNL_ARG_SRC</code>).</li>
</ul>
<dl class="section see"><dt>See Also</dt><dd>Please check tutorials below to see run-time attributes in use.</dd></dl>
<h2>Implementation Limitations</h2>
<ol type="1">
<li>Check <a class="el" href="dev_guide_data_types.html">Data Types</a>.</li>
<li>The CPU engine doesn't support <code>u8</code> data type for weights.</li>
</ol>
<h2>Performance Tips</h2>
<ul>
<li>Use <a class="el" href="structdnnl_1_1memory.html#a8e71077ed6a5f7fb7b3e6e1a5a2ecf3fa100b8cad7cf2a56f6df78f171f97a1ec" title="Placeholder memory format tag. ">dnnl::memory::format_tag::any</a> for either of the input tensors if and only if the shape of the corresponding tensor is fully known at creation time and it is possible to cache reordered tensors across multiple primitive executions. For instance, a good candidate for reuse are the weights tensors during inference: their shapes and data types are known in advance; thus they can be reordered during the first inference pass and can be reused during the subsequent passes. However, if any of the input tensors cannot be reused, it is best to force the primitive to use the same format as that used by the tensors.</li>
</ul>
<h2>Examples</h2>
<table class="doxtable">
<tr>
<th align="left">Engine </th><th align="left">Name </th><th align="left">Comments  </th></tr>
<tr>
<td align="left">CPU/GPU </td><td align="left"><a class="el" href="matmul_example_cpp.html">Matmul Primitive Example</a> </td><td align="left"><p class="starttd">This C++ API example demonstrates how to create and execute a <a class="el" href="dev_guide_matmul.html">MatMul</a> primitive.</p>
<p class="endtd">Key optimizations included in this example:</p>
<ul>
<li>Primitive attributes with fused post-ops. </li>
</ul>
</td></tr>
<tr>
<td align="left">CPU </td><td align="left"><a class="el" href="cpu_sgemm_and_matmul_cpp.html">MatMul Tutorial: Comparison with SGEMM</a> </td><td align="left"><p class="starttd">C++ API example demonstrating <a class="el" href="dev_guide_matmul.html">MatMul</a> as a replacement for SGEMM functions.</p>
<p class="endtd">Concepts:</p>
<ul>
<li>Create primitive once, use multiple times<ul>
<li>Run-time tensor shapes: <a class="el" href="group__dnnl__api__memory.html#gaa596c5a6102df77a550bad98f0d5cc12" title="A wildcard value for dimensions that are unknown at a primitive creation time. ">DNNL_RUNTIME_DIM_VAL</a></li>
<li>Run-time output scales: <a class="el" href="structdnnl_1_1primitive__attr.html#a4b81acc8e48886313154f75c1708ae02" title="Sets output scaling factors correspondence mask and values. ">dnnl::primitive_attr::set_output_scales()</a> and <a class="el" href="group__dnnl__api__memory.html#gab16365c11b4dc88fbb453edb51f1979f" title="A wildcard value for floating point values that are unknown at a primitive creation time...">DNNL_RUNTIME_F32_VAL</a> </li>
</ul>
</li>
</ul>
</td></tr>
<tr>
<td align="left">CPU/GPU </td><td align="left"><a class="el" href="inference_int8_matmul_cpp.html">MatMul Tutorial: INT8 Inference</a> </td><td align="left"><p class="starttd">C++ API example demonstrating how one can use <a class="el" href="dev_guide_matmul.html">MatMul</a> fused with ReLU in INT8 inference.</p>
<p class="endtd">Concepts:</p>
<ul>
<li>Asymmetric quantization<ul>
<li>Run-time output scales: <a class="el" href="structdnnl_1_1primitive__attr.html#a4b81acc8e48886313154f75c1708ae02" title="Sets output scaling factors correspondence mask and values. ">dnnl::primitive_attr::set_output_scales()</a> and <a class="el" href="group__dnnl__api__memory.html#gab16365c11b4dc88fbb453edb51f1979f" title="A wildcard value for floating point values that are unknown at a primitive creation time...">DNNL_RUNTIME_F32_VAL</a></li>
<li>Run-time zero points: <a class="el" href="structdnnl_1_1primitive__attr.html#aee82deb014cf9702ceb3e725156c25a1" title="Sets zero points for primitive operations for a given memory argument. ">dnnl::primitive_attr::set_zero_points()</a> and <a class="el" href="group__dnnl__api__memory.html#ga30139d5110e9e895ccd93fe503ca4c35" title="A wildcard value for int32_t values that are unknown at a primitive creation time. ">DNNL_RUNTIME_S32_VAL</a></li>
</ul>
</li>
<li><a class="el" href="dev_guide_attributes_post_ops.html">Operation fusion</a></li>
<li>Create primitive once, use multiple times<ul>
<li>Run-time tensor shapes: <a class="el" href="group__dnnl__api__memory.html#gaa596c5a6102df77a550bad98f0d5cc12" title="A wildcard value for dimensions that are unknown at a primitive creation time. ">DNNL_RUNTIME_DIM_VAL</a></li>
</ul>
</li>
<li>Weights pre-packing: use <a class="el" href="structdnnl_1_1memory.html#a8e71077ed6a5f7fb7b3e6e1a5a2ecf3fa100b8cad7cf2a56f6df78f171f97a1ec" title="Placeholder memory format tag. ">dnnl::memory::format_tag::any</a> </li>
</ul>
</td></tr>
<tr>
<td align="left">CPU </td><td align="left"><a class="el" href="cpu_matmul_quantization_cpp.html">MatMul Tutorial: Quantization</a> </td><td align="left"><p class="starttd">C++ API example demonstrating how one can perform reduced precision matrix-matrix multiplication using <a class="el" href="dev_guide_matmul.html">MatMul</a> and the accuracy of the result compared to the floating point computations.</p>
<p class="endtd">Concepts:</p>
<ul>
<li><b>Static</b> and <b>dynamic</b> quantization</li>
<li>Asymmetric quantization<ul>
<li>Run-time output scales: <a class="el" href="structdnnl_1_1primitive__attr.html#a4b81acc8e48886313154f75c1708ae02" title="Sets output scaling factors correspondence mask and values. ">dnnl::primitive_attr::set_output_scales()</a> and <a class="el" href="group__dnnl__api__memory.html#gab16365c11b4dc88fbb453edb51f1979f" title="A wildcard value for floating point values that are unknown at a primitive creation time...">DNNL_RUNTIME_F32_VAL</a></li>
<li>Run-time zero points: <a class="el" href="structdnnl_1_1primitive__attr.html#aee82deb014cf9702ceb3e725156c25a1" title="Sets zero points for primitive operations for a given memory argument. ">dnnl::primitive_attr::set_zero_points()</a> and <a class="el" href="group__dnnl__api__memory.html#ga30139d5110e9e895ccd93fe503ca4c35" title="A wildcard value for int32_t values that are unknown at a primitive creation time. ">DNNL_RUNTIME_S32_VAL</a> </li>
</ul>
</li>
</ul>
</td></tr>
</table>
</div></div><!-- contents -->
<div class="footer">
    <div class="footer-wrapper">
        <ul id="footer-links">
            <li><a href="legal_information.html">Legal information</a></li>
        </ul>
    </div>
</div>