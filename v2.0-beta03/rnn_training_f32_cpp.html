<!-- HTML header for doxygen 1.8.5-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.5"/>
<title>DNNL: RNN f32 training example</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<script src="assets/mathjax/MathJax.js?config=TeX-AMS_CHTML"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Montserrat" rel="stylesheet">
<link href="assets/customdoxygen.css" rel="stylesheet" type="text/css" />
<script type="text/javascript" src="assets/dnn.js"></script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
   <div id="projectname">Deep Neural Network Library (DNNL)
   &#160;<span id="projectnumber">1.90.1</span>
   </div>
   <div id="projectbrief">Performance library for Deep Learning</div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.5 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="modules.html"><span>Modules</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li><a href="examples.html"><span>Examples</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Typedefs</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(6)"><span class="SelectionMark">&#160;</span>Enumerations</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(7)"><span class="SelectionMark">&#160;</span>Enumerator</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(8)"><span class="SelectionMark">&#160;</span>Groups</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(9)"><span class="SelectionMark">&#160;</span>Pages</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">RNN f32 training example </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>This C++ API example demonstrates how to build GNMT model training.</p>
<div class="fragment"><div class="line"><span class="comment">/*******************************************************************************</span></div>
<div class="line"><span class="comment">* Copyright 2018-2019 Intel Corporation</span></div>
<div class="line"><span class="comment">*</span></div>
<div class="line"><span class="comment">* Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></div>
<div class="line"><span class="comment">* you may not use this file except in compliance with the License.</span></div>
<div class="line"><span class="comment">* You may obtain a copy of the License at</span></div>
<div class="line"><span class="comment">*</span></div>
<div class="line"><span class="comment">*     http://www.apache.org/licenses/LICENSE-2.0</span></div>
<div class="line"><span class="comment">*</span></div>
<div class="line"><span class="comment">* Unless required by applicable law or agreed to in writing, software</span></div>
<div class="line"><span class="comment">* distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></div>
<div class="line"><span class="comment">* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></div>
<div class="line"><span class="comment">* See the License for the specific language governing permissions and</span></div>
<div class="line"><span class="comment">* limitations under the License.</span></div>
<div class="line"><span class="comment">*******************************************************************************/</span></div>
<div class="line"></div>
<div class="line"></div>
<div class="line"><span class="preprocessor">#include &lt;cstring&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;math.h&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;numeric&gt;</span></div>
<div class="line"></div>
<div class="line"><span class="preprocessor">#include &quot;example_utils.hpp&quot;</span></div>
<div class="line"></div>
<div class="line"><span class="keyword">using namespace </span>dnnl;</div>
<div class="line"></div>
<div class="line"><span class="comment">// User input is:</span></div>
<div class="line"><span class="comment">//     N0 sequences of length T0</span></div>
<div class="line"><span class="keyword">const</span> <span class="keywordtype">int</span> N0 = 1 + rand() % 31;</div>
<div class="line"><span class="comment">//     N1 sequences of length T1</span></div>
<div class="line"><span class="keyword">const</span> <span class="keywordtype">int</span> N1 = 1 + rand() % 31;</div>
<div class="line"><span class="comment">// Assume T0 &gt; T1</span></div>
<div class="line"><span class="keyword">const</span> <span class="keywordtype">int</span> T0 = 31 + 1 + rand() % 31;</div>
<div class="line"><span class="keyword">const</span> <span class="keywordtype">int</span> T1 = 1 + rand() % 31;</div>
<div class="line"></div>
<div class="line"><span class="comment">// Memory required to hold it: N0 * T0 + N1 * T1</span></div>
<div class="line"><span class="comment">// However it is possible to have these coming</span></div>
<div class="line"><span class="comment">// as padded chunks in larger memory:</span></div>
<div class="line"><span class="comment">//      e.g. (N0 + N1) * T0</span></div>
<div class="line"><span class="comment">// We don&#39;t need to compact the data before processing,</span></div>
<div class="line"><span class="comment">// we can address the chunks via sub-memory and</span></div>
<div class="line"><span class="comment">// process the data via two RNN primitives:</span></div>
<div class="line"><span class="comment">//     of time lengths T1 and T0 - T1.</span></div>
<div class="line"><span class="comment">// The leftmost primitive will process N0 + N1 subsequences of length T1</span></div>
<div class="line"><span class="comment">// The rightmost primitive will process remaining N0 subsequences</span></div>
<div class="line"><span class="comment">// of T0 - T1 length</span></div>
<div class="line"><span class="keyword">const</span> <span class="keywordtype">int</span> leftmost_batch = N0 + N1;</div>
<div class="line"><span class="keyword">const</span> <span class="keywordtype">int</span> rightmost_batch = N0;</div>
<div class="line"></div>
<div class="line"><span class="keyword">const</span> <span class="keywordtype">int</span> leftmost_seq_length = T1;</div>
<div class="line"><span class="keyword">const</span> <span class="keywordtype">int</span> rightmost_seq_length = T0 - T1;</div>
<div class="line"></div>
<div class="line"><span class="comment">// Number of channels</span></div>
<div class="line"><span class="keyword">const</span> <span class="keywordtype">int</span> common_feature_size = 1024;</div>
<div class="line"></div>
<div class="line"><span class="comment">// RNN primitive characteristics</span></div>
<div class="line"><span class="keyword">const</span> <span class="keywordtype">int</span> common_n_layers = 1;</div>
<div class="line"><span class="keyword">const</span> <span class="keywordtype">int</span> lstm_n_gates = 4;</div>
<div class="line"></div>
<div class="line"><span class="keywordtype">void</span> simple_net(<a class="code" href="structdnnl_1_1engine.html#a2635da16314dcbdb9bd9ea431316bb1a">engine::kind</a> engine_kind) {</div>
<div class="line">    <span class="keyword">using</span> tag = <a class="code" href="structdnnl_1_1memory.html#a8e71077ed6a5f7fb7b3e6e1a5a2ecf3f">memory::format_tag</a>;</div>
<div class="line">    <span class="keyword">using</span> dt = <a class="code" href="structdnnl_1_1memory.html#a8e83474ec3a50e08e37af76c8c075dce">memory::data_type</a>;</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> eng = <a class="code" href="group__cpp__api__enums.html#gga94efdd650364f4d9776cfb9b711cbdc1aad1943a9fd6d3d7ee1e6af41a5b0d3e7">engine</a>(engine_kind, 0);</div>
<div class="line">    stream s(eng);</div>
<div class="line"></div>
<div class="line">    <span class="keywordtype">bool</span> is_training = <span class="keyword">true</span>;</div>
<div class="line">    <span class="keyword">auto</span> fwd_inf_train = is_training ? <a class="code" href="group__cpp__api__enums.html#ggac7db48f6583aa9903e54c2a39d65438fa24775787fab8f13aa4809e1ce8f82aeb">prop_kind::forward_training</a></div>
<div class="line">                                     : <a class="code" href="group__cpp__api__enums.html#ggac7db48f6583aa9903e54c2a39d65438fa3b9fad4f80d45368f856b5403198ac4c">prop_kind::forward_inference</a>;</div>
<div class="line"></div>
<div class="line">    std::vector&lt;primitive&gt; fwd_net;</div>
<div class="line">    std::vector&lt;primitive&gt; bwd_net;</div>
<div class="line"></div>
<div class="line">    <span class="comment">// Input tensor holds two batches with different sequence lengths.</span></div>
<div class="line">    <span class="comment">// Shorter sequences are padded</span></div>
<div class="line">    memory::dims net_src_dims = {</div>
<div class="line">            T0, <span class="comment">// time, maximum sequence length</span></div>
<div class="line">            N0 + N1, <span class="comment">// n, total batch size</span></div>
<div class="line">            common_feature_size <span class="comment">// c, common number of channels</span></div>
<div class="line">    };</div>
<div class="line"></div>
<div class="line">    <span class="comment">// Two RNN primitives for different sequence lengths,</span></div>
<div class="line">    <span class="comment">// one unidirectional layer, LSTM-based</span></div>
<div class="line">    memory::dims leftmost_src_layer_dims = {</div>
<div class="line">            leftmost_seq_length, <span class="comment">// time</span></div>
<div class="line">            leftmost_batch, <span class="comment">// n</span></div>
<div class="line">            common_feature_size <span class="comment">// c</span></div>
<div class="line">    };</div>
<div class="line">    memory::dims rightmost_src_layer_dims = {</div>
<div class="line">            rightmost_seq_length, <span class="comment">// time</span></div>
<div class="line">            rightmost_batch, <span class="comment">// n</span></div>
<div class="line">            common_feature_size <span class="comment">// c</span></div>
<div class="line">    };</div>
<div class="line">    memory::dims common_weights_layer_dims = {</div>
<div class="line">            common_n_layers, <span class="comment">// layers</span></div>
<div class="line">            1, <span class="comment">// directions</span></div>
<div class="line">            common_feature_size, <span class="comment">// input feature size</span></div>
<div class="line">            lstm_n_gates, <span class="comment">// gates number</span></div>
<div class="line">            common_feature_size <span class="comment">// output feature size</span></div>
<div class="line">    };</div>
<div class="line">    memory::dims common_weights_iter_dims = {</div>
<div class="line">            common_n_layers, <span class="comment">// layers</span></div>
<div class="line">            1, <span class="comment">// directions</span></div>
<div class="line">            common_feature_size, <span class="comment">// input feature size</span></div>
<div class="line">            lstm_n_gates, <span class="comment">// gates number</span></div>
<div class="line">            common_feature_size <span class="comment">// output feature size</span></div>
<div class="line">    };</div>
<div class="line">    memory::dims common_bias_dims = {</div>
<div class="line">            common_n_layers, <span class="comment">// layers</span></div>
<div class="line">            1, <span class="comment">// directions</span></div>
<div class="line">            lstm_n_gates, <span class="comment">// gates number</span></div>
<div class="line">            common_feature_size <span class="comment">// output feature size</span></div>
<div class="line">    };</div>
<div class="line">    memory::dims leftmost_dst_layer_dims = {</div>
<div class="line">            leftmost_seq_length, <span class="comment">// time</span></div>
<div class="line">            leftmost_batch, <span class="comment">// n</span></div>
<div class="line">            common_feature_size <span class="comment">// c</span></div>
<div class="line">    };</div>
<div class="line">    memory::dims rightmost_dst_layer_dims = {</div>
<div class="line">            rightmost_seq_length, <span class="comment">// time</span></div>
<div class="line">            rightmost_batch, <span class="comment">// n</span></div>
<div class="line">            common_feature_size <span class="comment">// c</span></div>
<div class="line">    };</div>
<div class="line"></div>
<div class="line">    <span class="comment">// leftmost primitive passes its states to the next RNN iteration</span></div>
<div class="line">    <span class="comment">// so it needs dst_iter parameter.</span></div>
<div class="line">    <span class="comment">//</span></div>
<div class="line">    <span class="comment">// rightmost primitive will consume these as src_iter and will access the</span></div>
<div class="line">    <span class="comment">// memory via a sub-memory because it will have different batch dimension.</span></div>
<div class="line">    <span class="comment">// We have arranged our primitives so that</span></div>
<div class="line">    <span class="comment">// leftmost_batch &gt;= rightmost_batch, and so the rightmost data will fit</span></div>
<div class="line">    <span class="comment">// into the memory allocated for the leftmost.</span></div>
<div class="line">    memory::dims leftmost_dst_iter_dims = {</div>
<div class="line">            common_n_layers, <span class="comment">// layers</span></div>
<div class="line">            1, <span class="comment">// directions</span></div>
<div class="line">            leftmost_batch, <span class="comment">// n</span></div>
<div class="line">            common_feature_size <span class="comment">// c</span></div>
<div class="line">    };</div>
<div class="line">    memory::dims leftmost_dst_iter_c_dims = {</div>
<div class="line">            common_n_layers, <span class="comment">// layers</span></div>
<div class="line">            1, <span class="comment">// directions</span></div>
<div class="line">            leftmost_batch, <span class="comment">// n</span></div>
<div class="line">            common_feature_size <span class="comment">// c</span></div>
<div class="line">    };</div>
<div class="line">    memory::dims rightmost_src_iter_dims = {</div>
<div class="line">            common_n_layers, <span class="comment">// layers</span></div>
<div class="line">            1, <span class="comment">// directions</span></div>
<div class="line">            rightmost_batch, <span class="comment">// n</span></div>
<div class="line">            common_feature_size <span class="comment">// c</span></div>
<div class="line">    };</div>
<div class="line">    memory::dims rightmost_src_iter_c_dims = {</div>
<div class="line">            common_n_layers, <span class="comment">// layers</span></div>
<div class="line">            1, <span class="comment">// directions</span></div>
<div class="line">            rightmost_batch, <span class="comment">// n</span></div>
<div class="line">            common_feature_size <span class="comment">// c</span></div>
<div class="line">    };</div>
<div class="line"></div>
<div class="line">    <span class="comment">// multiplication of tensor dimensions</span></div>
<div class="line">    <span class="keyword">auto</span> tz_volume = [=](memory::dims tz_dims) {</div>
<div class="line">        <span class="keywordflow">return</span> std::accumulate(tz_dims.begin(), tz_dims.end(), (memory::dim)1,</div>
<div class="line">                std::multiplies&lt;memory::dim&gt;());</div>
<div class="line">    };</div>
<div class="line"></div>
<div class="line">    <span class="comment">// Create auxillary f32 memory descriptor</span></div>
<div class="line">    <span class="comment">// based on user- supplied dimensions and layout.</span></div>
<div class="line">    <span class="keyword">auto</span> formatted_md</div>
<div class="line">            = [=](memory::dims dimensions, <a class="code" href="structdnnl_1_1memory.html#a8e71077ed6a5f7fb7b3e6e1a5a2ecf3f">memory::format_tag</a> layout) {</div>
<div class="line">                  <span class="keywordflow">return</span> <a class="code" href="structdnnl_1_1memory_1_1desc.html">memory::desc</a> {{dimensions}, dt::f32, layout};</div>
<div class="line">              };</div>
<div class="line">    <span class="comment">// Create auxillary generic f32 memory descriptor</span></div>
<div class="line">    <span class="comment">// based on supplied dimensions, with format_tag::any.</span></div>
<div class="line">    <span class="keyword">auto</span> generic_md = [=](memory::dims dimensions) {</div>
<div class="line">        <span class="keywordflow">return</span> formatted_md(dimensions, tag::any);</div>
<div class="line">    };</div>
<div class="line"></div>
<div class="line">    <span class="comment">//</span></div>
<div class="line">    <span class="comment">// I/O memory, coming from user</span></div>
<div class="line">    <span class="comment">//</span></div>
<div class="line"></div>
<div class="line">    <span class="comment">// Net input</span></div>
<div class="line">    std::vector&lt;float&gt; net_src(tz_volume(net_src_dims), 1.0f);</div>
<div class="line">    <span class="comment">// NOTE: in this example we study input sequences with variable batch</span></div>
<div class="line">    <span class="comment">// dimension, which get processed by two separate RNN primitives, thus</span></div>
<div class="line">    <span class="comment">// the destination memory for the two will have different shapes: batch</span></div>
<div class="line">    <span class="comment">// is the second dimension currently: see format_tag::tnc.</span></div>
<div class="line">    <span class="comment">// We are not copying the output to some common user provided memory as we</span></div>
<div class="line">    <span class="comment">// suggest that the user should rather keep the two output memories separate</span></div>
<div class="line">    <span class="comment">// throughout the whole topology and only reorder to something else as</span></div>
<div class="line">    <span class="comment">// needed.</span></div>
<div class="line">    <span class="comment">// So there&#39;s no common net_dst, but there are two destinations instead:</span></div>
<div class="line">    <span class="comment">//    leftmost_dst_layer_memory</span></div>
<div class="line">    <span class="comment">//    rightmost_dst_layer_memory</span></div>
<div class="line"></div>
<div class="line">    <span class="comment">// Memory for the user allocated memory</span></div>
<div class="line">    <span class="comment">// Suppose user data is in tnc format.</span></div>
<div class="line">    <span class="keyword">auto</span> net_src_memory</div>
<div class="line">            = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>({{net_src_dims}, dt::f32, tag::tnc}, eng);</div>
<div class="line">    write_to_dnnl_memory(net_src.data(), net_src_memory);</div>
<div class="line">    <span class="comment">// src_layer memory of the leftmost and rightmost RNN primitives</span></div>
<div class="line">    <span class="comment">// are accessed through the respective sub-memories in larger memory.</span></div>
<div class="line">    <span class="comment">// View primitives compute the strides to accommodate for padding.</span></div>
<div class="line">    <span class="keyword">auto</span> user_leftmost_src_layer_md = net_src_memory.get_desc().submemory_desc(</div>
<div class="line">            leftmost_src_layer_dims, {0, 0, 0}); <span class="comment">// t, n, c offsets</span></div>
<div class="line">    <span class="keyword">auto</span> user_rightmost_src_layer_md</div>
<div class="line">            = net_src_memory.get_desc().submemory_desc(rightmost_src_layer_dims,</div>
<div class="line">                    {leftmost_seq_length, 0, 0}); <span class="comment">// t, n, c offsets</span></div>
<div class="line">    <span class="keyword">auto</span> leftmost_src_layer_memory = net_src_memory;</div>
<div class="line">    <span class="keyword">auto</span> rightmost_src_layer_memory = net_src_memory;</div>
<div class="line"></div>
<div class="line">    <span class="comment">// Other user provided memory arrays, descriptors and primitives with the</span></div>
<div class="line">    <span class="comment">// data layouts chosen by user. We&#39;ll have to reorder if RNN</span></div>
<div class="line">    <span class="comment">// primitive prefers it in a different format.</span></div>
<div class="line">    std::vector&lt;float&gt; user_common_weights_layer(</div>
<div class="line">            tz_volume(common_weights_layer_dims), 1.0f);</div>
<div class="line">    <span class="keyword">auto</span> user_common_weights_layer_memory = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>(</div>
<div class="line">            {common_weights_layer_dims, dt::f32, tag::ldigo}, eng);</div>
<div class="line">    write_to_dnnl_memory(</div>
<div class="line">            user_common_weights_layer.data(), user_common_weights_layer_memory);</div>
<div class="line"></div>
<div class="line">    std::vector&lt;float&gt; user_common_weights_iter(</div>
<div class="line">            tz_volume(common_weights_iter_dims), 1.0f);</div>
<div class="line">    <span class="keyword">auto</span> user_common_weights_iter_memory = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>(</div>
<div class="line">            {{common_weights_iter_dims}, dt::f32, tag::ldigo}, eng);</div>
<div class="line">    write_to_dnnl_memory(</div>
<div class="line">            user_common_weights_layer.data(), user_common_weights_iter_memory);</div>
<div class="line"></div>
<div class="line">    std::vector&lt;float&gt; user_common_bias(tz_volume(common_bias_dims), 1.0f);</div>
<div class="line">    <span class="keyword">auto</span> user_common_bias_memory</div>
<div class="line">            = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>({{common_bias_dims}, dt::f32, tag::ldgo}, eng);</div>
<div class="line">    write_to_dnnl_memory(user_common_bias.data(), user_common_bias_memory);</div>
<div class="line"></div>
<div class="line">    std::vector&lt;float&gt; user_leftmost_dst_layer(</div>
<div class="line">            tz_volume(leftmost_dst_layer_dims), 1.0f);</div>
<div class="line">    <span class="keyword">auto</span> user_leftmost_dst_layer_memory</div>
<div class="line">            = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>({{leftmost_dst_layer_dims}, dt::f32, tag::tnc}, eng);</div>
<div class="line">    write_to_dnnl_memory(</div>
<div class="line">            user_leftmost_dst_layer.data(), user_leftmost_dst_layer_memory);</div>
<div class="line"></div>
<div class="line">    std::vector&lt;float&gt; user_rightmost_dst_layer(</div>
<div class="line">            tz_volume(rightmost_dst_layer_dims), 1.0f);</div>
<div class="line">    <span class="keyword">auto</span> user_rightmost_dst_layer_memory = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>(</div>
<div class="line">            {{rightmost_dst_layer_dims}, dt::f32, tag::tnc}, eng);</div>
<div class="line">    write_to_dnnl_memory(</div>
<div class="line">            user_rightmost_dst_layer.data(), user_rightmost_dst_layer_memory);</div>
<div class="line"></div>
<div class="line">    <span class="comment">// Describe layer, forward pass, leftmost primitive.</span></div>
<div class="line">    <span class="comment">// There are no primitives to the left from here,</span></div>
<div class="line">    <span class="comment">// so src_iter_desc needs to be zero memory desc</span></div>
<div class="line">    <a class="code" href="structdnnl_1_1lstm__forward_1_1desc.html">lstm_forward::desc</a> leftmost_layer_desc(fwd_inf_train, <span class="comment">// aprop_kind</span></div>
<div class="line">            rnn_direction::unidirectional_left2right, <span class="comment">// direction</span></div>
<div class="line">            user_leftmost_src_layer_md, <span class="comment">// src_layer_desc</span></div>
<div class="line">            <a class="code" href="structdnnl_1_1memory_1_1desc.html">memory::desc</a>(), <span class="comment">// src_iter_desc</span></div>
<div class="line">            <a class="code" href="structdnnl_1_1memory_1_1desc.html">memory::desc</a>(), <span class="comment">// src_iter_c_desc</span></div>
<div class="line">            generic_md(common_weights_layer_dims), <span class="comment">// weights_layer_desc</span></div>
<div class="line">            generic_md(common_weights_iter_dims), <span class="comment">// weights_iter_desc</span></div>
<div class="line">            generic_md(common_bias_dims), <span class="comment">// bias_desc</span></div>
<div class="line">            formatted_md(leftmost_dst_layer_dims, tag::tnc), <span class="comment">// dst_layer_desc</span></div>
<div class="line">            generic_md(leftmost_dst_iter_dims), <span class="comment">// dst_iter_desc</span></div>
<div class="line">            generic_md(leftmost_dst_iter_c_dims) <span class="comment">// dst_iter_c_desc</span></div>
<div class="line">    );</div>
<div class="line">    <span class="comment">// Describe primitive</span></div>
<div class="line">    <span class="keyword">auto</span> leftmost_prim_desc</div>
<div class="line">            = <a class="code" href="structdnnl_1_1lstm__forward_1_1primitive__desc.html">dnnl::lstm_forward::primitive_desc</a>(leftmost_layer_desc, eng);</div>
<div class="line"></div>
<div class="line">    <span class="comment">//</span></div>
<div class="line">    <span class="comment">// Need to connect leftmost and rightmost via &quot;iter&quot; parameters.</span></div>
<div class="line">    <span class="comment">// We allocate memory here based on the shapes provided by RNN primitive.</span></div>
<div class="line">    <span class="comment">//</span></div>
<div class="line">    <span class="keyword">auto</span> leftmost_dst_iter_memory</div>
<div class="line">            = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>(leftmost_prim_desc.dst_iter_desc(), eng);</div>
<div class="line">    <span class="keyword">auto</span> leftmost_dst_iter_c_memory</div>
<div class="line">            = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>(leftmost_prim_desc.dst_iter_c_desc(), eng);</div>
<div class="line"></div>
<div class="line">    <span class="comment">// rightmost src_iter will be a sub-memory of dst_iter of leftmost</span></div>
<div class="line">    <span class="keyword">auto</span> rightmost_src_iter_md</div>
<div class="line">            = leftmost_dst_iter_memory.get_desc().submemory_desc(</div>
<div class="line">                    rightmost_src_iter_dims,</div>
<div class="line">                    {0, 0, 0, 0}); <span class="comment">// l, d, n, c offsets</span></div>
<div class="line">    <span class="keyword">auto</span> rightmost_src_iter_memory = leftmost_dst_iter_memory;</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> rightmost_src_iter_c_md</div>
<div class="line">            = leftmost_dst_iter_c_memory.get_desc().submemory_desc(</div>
<div class="line">                    rightmost_src_iter_c_dims,</div>
<div class="line">                    {0, 0, 0, 0}); <span class="comment">// l, d, n, c offsets</span></div>
<div class="line">    <span class="keyword">auto</span> rightmost_src_iter_c_memory = leftmost_dst_iter_c_memory;</div>
<div class="line"></div>
<div class="line">    <span class="comment">// Now rightmost primitive</span></div>
<div class="line">    <span class="comment">// There are no primitives to the right from here,</span></div>
<div class="line">    <span class="comment">// so dst_iter_desc is explicit zero memory desc</span></div>
<div class="line">    <a class="code" href="structdnnl_1_1lstm__forward_1_1desc.html">lstm_forward::desc</a> rightmost_layer_desc(fwd_inf_train, <span class="comment">// aprop_kind</span></div>
<div class="line">            rnn_direction::unidirectional_left2right, <span class="comment">// direction</span></div>
<div class="line">            user_rightmost_src_layer_md, <span class="comment">// src_layer_desc</span></div>
<div class="line">            rightmost_src_iter_md, <span class="comment">// src_iter_desc</span></div>
<div class="line">            rightmost_src_iter_c_md, <span class="comment">// src_iter_c_desc</span></div>
<div class="line">            generic_md(common_weights_layer_dims), <span class="comment">// weights_layer_desc</span></div>
<div class="line">            generic_md(common_weights_iter_dims), <span class="comment">// weights_iter_desc</span></div>
<div class="line">            generic_md(common_bias_dims), <span class="comment">// bias_desc</span></div>
<div class="line">            formatted_md(rightmost_dst_layer_dims, tag::tnc), <span class="comment">// dst_layer_desc</span></div>
<div class="line">            <a class="code" href="structdnnl_1_1memory_1_1desc.html">memory::desc</a>(), <span class="comment">// dst_iter_desc</span></div>
<div class="line">            <a class="code" href="structdnnl_1_1memory_1_1desc.html">memory::desc</a>() <span class="comment">// dst_iter_c_desc</span></div>
<div class="line">    );</div>
<div class="line">    <span class="keyword">auto</span> rightmost_prim_desc</div>
<div class="line">            = <a class="code" href="structdnnl_1_1lstm__forward_1_1primitive__desc.html">lstm_forward::primitive_desc</a>(rightmost_layer_desc, eng);</div>
<div class="line"></div>
<div class="line">    <span class="comment">//</span></div>
<div class="line">    <span class="comment">// Weights and biases, layer memory</span></div>
<div class="line">    <span class="comment">// Same layout should work across the layer, no reorders</span></div>
<div class="line">    <span class="comment">// needed between leftmost and rigthmost, only reordering</span></div>
<div class="line">    <span class="comment">// user memory to the RNN-friendly shapes.</span></div>
<div class="line">    <span class="comment">//</span></div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> common_weights_layer_memory = user_common_weights_layer_memory;</div>
<div class="line">    <span class="keywordflow">if</span> (leftmost_prim_desc.weights_layer_desc()</div>
<div class="line">            != common_weights_layer_memory.get_desc()) {</div>
<div class="line">        common_weights_layer_memory</div>
<div class="line">                = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>(leftmost_prim_desc.weights_layer_desc(), eng);</div>
<div class="line">        reorder(user_common_weights_layer_memory, common_weights_layer_memory)</div>
<div class="line">                .execute(s, user_common_weights_layer_memory,</div>
<div class="line">                        common_weights_layer_memory);</div>
<div class="line">    }</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> common_weights_iter_memory = user_common_weights_iter_memory;</div>
<div class="line">    <span class="keywordflow">if</span> (leftmost_prim_desc.weights_iter_desc()</div>
<div class="line">            != common_weights_iter_memory.get_desc()) {</div>
<div class="line">        common_weights_iter_memory</div>
<div class="line">                = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>(leftmost_prim_desc.weights_iter_desc(), eng);</div>
<div class="line">        reorder(user_common_weights_iter_memory, common_weights_iter_memory)</div>
<div class="line">                .execute(s, user_common_weights_iter_memory,</div>
<div class="line">                        common_weights_iter_memory);</div>
<div class="line">    }</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> common_bias_memory = user_common_bias_memory;</div>
<div class="line">    <span class="keywordflow">if</span> (leftmost_prim_desc.bias_desc() != common_bias_memory.get_desc()) {</div>
<div class="line">        common_bias_memory = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>(leftmost_prim_desc.bias_desc(), eng);</div>
<div class="line">        reorder(user_common_bias_memory, common_bias_memory)</div>
<div class="line">                .execute(s, user_common_bias_memory, common_bias_memory);</div>
<div class="line">    }</div>
<div class="line"></div>
<div class="line">    <span class="comment">//</span></div>
<div class="line">    <span class="comment">// Destination layer memory</span></div>
<div class="line">    <span class="comment">//</span></div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> leftmost_dst_layer_memory = user_leftmost_dst_layer_memory;</div>
<div class="line">    <span class="keywordflow">if</span> (leftmost_prim_desc.dst_layer_desc()</div>
<div class="line">            != leftmost_dst_layer_memory.get_desc()) {</div>
<div class="line">        leftmost_dst_layer_memory</div>
<div class="line">                = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>(leftmost_prim_desc.dst_layer_desc(), eng);</div>
<div class="line">        reorder(user_leftmost_dst_layer_memory, leftmost_dst_layer_memory)</div>
<div class="line">                .execute(s, user_leftmost_dst_layer_memory,</div>
<div class="line">                        leftmost_dst_layer_memory);</div>
<div class="line">    }</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> rightmost_dst_layer_memory = user_rightmost_dst_layer_memory;</div>
<div class="line">    <span class="keywordflow">if</span> (rightmost_prim_desc.dst_layer_desc()</div>
<div class="line">            != rightmost_dst_layer_memory.get_desc()) {</div>
<div class="line">        rightmost_dst_layer_memory</div>
<div class="line">                = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>(rightmost_prim_desc.dst_layer_desc(), eng);</div>
<div class="line">        reorder(user_rightmost_dst_layer_memory, rightmost_dst_layer_memory)</div>
<div class="line">                .execute(s, user_rightmost_dst_layer_memory,</div>
<div class="line">                        rightmost_dst_layer_memory);</div>
<div class="line">    }</div>
<div class="line"></div>
<div class="line">    <span class="comment">// We also create workspace memory based on the information from</span></div>
<div class="line">    <span class="comment">// the workspace_primitive_desc(). This is needed for internal</span></div>
<div class="line">    <span class="comment">// communication between forward and backward primitives during</span></div>
<div class="line">    <span class="comment">// training.</span></div>
<div class="line">    <span class="keyword">auto</span> create_ws = [=](<a class="code" href="structdnnl_1_1lstm__forward_1_1primitive__desc.html">dnnl::lstm_forward::primitive_desc</a> &amp;pd) {</div>
<div class="line">        <span class="keywordflow">return</span> <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>(pd.workspace_desc(), eng);</div>
<div class="line">    };</div>
<div class="line">    <span class="keyword">auto</span> leftmost_workspace_memory = create_ws(leftmost_prim_desc);</div>
<div class="line">    <span class="keyword">auto</span> rightmost_workspace_memory = create_ws(rightmost_prim_desc);</div>
<div class="line"></div>
<div class="line">    <span class="comment">// Construct the RNN primitive objects</span></div>
<div class="line">    <a class="code" href="structdnnl_1_1lstm__forward.html">lstm_forward</a> leftmost_layer(leftmost_prim_desc);</div>
<div class="line">    leftmost_layer.execute(s,</div>
<div class="line">            {{DNNL_ARG_SRC_LAYER, leftmost_src_layer_memory},</div>
<div class="line">                    {DNNL_ARG_WEIGHTS_LAYER, common_weights_layer_memory},</div>
<div class="line">                    {DNNL_ARG_WEIGHTS_ITER, common_weights_iter_memory},</div>
<div class="line">                    {DNNL_ARG_BIAS, common_bias_memory},</div>
<div class="line">                    {DNNL_ARG_DST_LAYER, leftmost_dst_layer_memory},</div>
<div class="line">                    {DNNL_ARG_DST_ITER, leftmost_dst_iter_memory},</div>
<div class="line">                    {DNNL_ARG_DST_ITER_C, leftmost_dst_iter_c_memory},</div>
<div class="line">                    {DNNL_ARG_WORKSPACE, leftmost_workspace_memory}});</div>
<div class="line"></div>
<div class="line">    <a class="code" href="structdnnl_1_1lstm__forward.html">lstm_forward</a> rightmost_layer(rightmost_prim_desc);</div>
<div class="line">    rightmost_layer.execute(s,</div>
<div class="line">            {{DNNL_ARG_SRC_LAYER, rightmost_src_layer_memory},</div>
<div class="line">                    {DNNL_ARG_SRC_ITER, rightmost_src_iter_memory},</div>
<div class="line">                    {DNNL_ARG_SRC_ITER_C, rightmost_src_iter_c_memory},</div>
<div class="line">                    {DNNL_ARG_WEIGHTS_LAYER, common_weights_layer_memory},</div>
<div class="line">                    {DNNL_ARG_WEIGHTS_ITER, common_weights_iter_memory},</div>
<div class="line">                    {DNNL_ARG_BIAS, common_bias_memory},</div>
<div class="line">                    {DNNL_ARG_DST_LAYER, rightmost_dst_layer_memory},</div>
<div class="line">                    {DNNL_ARG_WORKSPACE, rightmost_workspace_memory}});</div>
<div class="line"></div>
<div class="line">    <span class="comment">// No backward pass for inference</span></div>
<div class="line">    <span class="keywordflow">if</span> (!is_training) <span class="keywordflow">return</span>;</div>
<div class="line"></div>
<div class="line">    <span class="comment">//</span></div>
<div class="line">    <span class="comment">// Backward primitives will reuse memory from forward</span></div>
<div class="line">    <span class="comment">// and allocate/describe specifics here. Only relevant for training.</span></div>
<div class="line">    <span class="comment">//</span></div>
<div class="line"></div>
<div class="line">    <span class="comment">// User-provided memory for backward by data output</span></div>
<div class="line">    std::vector&lt;float&gt; net_diff_src(tz_volume(net_src_dims), 1.0f);</div>
<div class="line">    <span class="keyword">auto</span> net_diff_src_memory</div>
<div class="line">            = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>(formatted_md(net_src_dims, tag::tnc), eng);</div>
<div class="line">    write_to_dnnl_memory(net_diff_src.data(), net_diff_src_memory);</div>
<div class="line"></div>
<div class="line">    <span class="comment">// diff_src follows the same layout we have for net_src</span></div>
<div class="line">    <span class="keyword">auto</span> user_leftmost_diff_src_layer_md</div>
<div class="line">            = net_diff_src_memory.get_desc().submemory_desc(</div>
<div class="line">                    leftmost_src_layer_dims, {0, 0, 0}); <span class="comment">// t, n, c offsets</span></div>
<div class="line">    <span class="keyword">auto</span> user_rightmost_diff_src_layer_md</div>
<div class="line">            = net_diff_src_memory.get_desc().submemory_desc(</div>
<div class="line">                    rightmost_src_layer_dims,</div>
<div class="line">                    {leftmost_seq_length, 0, 0}); <span class="comment">// t, n, c offsets</span></div>
<div class="line">    <span class="keyword">auto</span> leftmost_diff_src_layer_memory = net_diff_src_memory;</div>
<div class="line">    <span class="keyword">auto</span> rightmost_diff_src_layer_memory = net_diff_src_memory;</div>
<div class="line"></div>
<div class="line">    <span class="comment">// User-provided memory for backpropagation by weights</span></div>
<div class="line">    std::vector&lt;float&gt; user_common_diff_weights_layer(</div>
<div class="line">            tz_volume(common_weights_layer_dims), 1.0f);</div>
<div class="line">    <span class="keyword">auto</span> user_common_diff_weights_layer_memory = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>(</div>
<div class="line">            formatted_md(common_weights_layer_dims, tag::ldigo), eng);</div>
<div class="line">    write_to_dnnl_memory(user_common_diff_weights_layer.data(),</div>
<div class="line">            user_common_diff_weights_layer_memory);</div>
<div class="line"></div>
<div class="line">    std::vector&lt;float&gt; user_common_diff_bias(tz_volume(common_bias_dims), 1.0f);</div>
<div class="line">    <span class="keyword">auto</span> user_common_diff_bias_memory</div>
<div class="line">            = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>(formatted_md(common_bias_dims, tag::ldgo), eng);</div>
<div class="line">    write_to_dnnl_memory(</div>
<div class="line">            user_common_diff_bias.data(), user_common_diff_bias_memory);</div>
<div class="line"></div>
<div class="line">    <span class="comment">// User-provided input to the backward primitive.</span></div>
<div class="line">    <span class="comment">// To be updated by the user after forward pass using some cost function.</span></div>
<div class="line">    memory::dims net_diff_dst_dims = {</div>
<div class="line">            T0, <span class="comment">// time</span></div>
<div class="line">            N0 + N1, <span class="comment">// n</span></div>
<div class="line">            common_feature_size <span class="comment">// c</span></div>
<div class="line">    };</div>
<div class="line">    <span class="comment">// Suppose user data is in tnc format.</span></div>
<div class="line">    std::vector&lt;float&gt; net_diff_dst(tz_volume(net_diff_dst_dims), 1.0f);</div>
<div class="line">    <span class="keyword">auto</span> net_diff_dst_memory</div>
<div class="line">            = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>(formatted_md(net_diff_dst_dims, tag::tnc), eng);</div>
<div class="line">    write_to_dnnl_memory(net_diff_dst.data(), net_diff_dst_memory);</div>
<div class="line">    <span class="comment">// diff_dst_layer memory of the leftmost and rightmost RNN primitives</span></div>
<div class="line">    <span class="comment">// are accessed through the respective sub-memory in larger memory.</span></div>
<div class="line">    <span class="comment">// View primitives compute the strides to accommodate for padding.</span></div>
<div class="line">    <span class="keyword">auto</span> user_leftmost_diff_dst_layer_md</div>
<div class="line">            = net_diff_dst_memory.get_desc().submemory_desc(</div>
<div class="line">                    leftmost_dst_layer_dims, {0, 0, 0}); <span class="comment">// t, n, c offsets</span></div>
<div class="line">    <span class="keyword">auto</span> user_rightmost_diff_dst_layer_md</div>
<div class="line">            = net_diff_dst_memory.get_desc().submemory_desc(</div>
<div class="line">                    rightmost_dst_layer_dims,</div>
<div class="line">                    {leftmost_seq_length, 0, 0}); <span class="comment">// t, n, c offsets</span></div>
<div class="line">    <span class="keyword">auto</span> leftmost_diff_dst_layer_memory = net_diff_dst_memory;</div>
<div class="line">    <span class="keyword">auto</span> rightmost_diff_dst_layer_memory = net_diff_dst_memory;</div>
<div class="line"></div>
<div class="line">    <span class="comment">// Backward leftmost primitive descriptor</span></div>
<div class="line">    <a class="code" href="structdnnl_1_1lstm__backward_1_1desc.html">lstm_backward::desc</a> leftmost_layer_bwd_desc(</div>
<div class="line">            <a class="code" href="group__cpp__api__enums.html#ggac7db48f6583aa9903e54c2a39d65438fa195fe59b6f103787a914aead0f3db502">prop_kind::backward</a>, <span class="comment">// aprop_kind</span></div>
<div class="line">            rnn_direction::unidirectional_left2right, <span class="comment">// direction</span></div>
<div class="line">            user_leftmost_src_layer_md, <span class="comment">// src_layer_desc</span></div>
<div class="line">            <a class="code" href="structdnnl_1_1memory_1_1desc.html">memory::desc</a>(), <span class="comment">// src_iter_desc</span></div>
<div class="line">            <a class="code" href="structdnnl_1_1memory_1_1desc.html">memory::desc</a>(), <span class="comment">// src_iter_c_desc</span></div>
<div class="line">            generic_md(common_weights_layer_dims), <span class="comment">// weights_layer_desc</span></div>
<div class="line">            generic_md(common_weights_iter_dims), <span class="comment">// weights_iter_desc</span></div>
<div class="line">            generic_md(common_bias_dims), <span class="comment">// bias_desc</span></div>
<div class="line">            formatted_md(leftmost_dst_layer_dims, tag::tnc), <span class="comment">// dst_layer_desc</span></div>
<div class="line">            generic_md(leftmost_dst_iter_dims), <span class="comment">// dst_iter_desc</span></div>
<div class="line">            generic_md(leftmost_dst_iter_c_dims), <span class="comment">// dst_iter_c_desc</span></div>
<div class="line">            user_leftmost_diff_src_layer_md, <span class="comment">// diff_src_layer_desc</span></div>
<div class="line">            <a class="code" href="structdnnl_1_1memory_1_1desc.html">memory::desc</a>(), <span class="comment">// diff_src_iter_desc</span></div>
<div class="line">            <a class="code" href="structdnnl_1_1memory_1_1desc.html">memory::desc</a>(), <span class="comment">// diff_src_iter_c_desc</span></div>
<div class="line">            generic_md(common_weights_layer_dims), <span class="comment">// diff_weights_layer_desc</span></div>
<div class="line">            generic_md(common_weights_iter_dims), <span class="comment">// diff_weights_iter_desc</span></div>
<div class="line">            generic_md(common_bias_dims), <span class="comment">// diff_bias_desc</span></div>
<div class="line">            user_leftmost_diff_dst_layer_md, <span class="comment">// diff_dst_layer_desc</span></div>
<div class="line">            generic_md(leftmost_dst_iter_dims), <span class="comment">// diff_dst_iter_desc</span></div>
<div class="line">            generic_md(leftmost_dst_iter_c_dims) <span class="comment">// diff_dst_iter_c_desc</span></div>
<div class="line">    );</div>
<div class="line">    <span class="keyword">auto</span> leftmost_bwd_prim_desc = <a class="code" href="structdnnl_1_1lstm__backward_1_1primitive__desc.html">lstm_backward::primitive_desc</a>(</div>
<div class="line">            leftmost_layer_bwd_desc, eng, leftmost_prim_desc);</div>
<div class="line"></div>
<div class="line">    <span class="comment">// As the batch dimensions are different between leftmost and rightmost</span></div>
<div class="line">    <span class="comment">// we need to use a sub-memory. rightmost needs less memory, so it will</span></div>
<div class="line">    <span class="comment">// be a sub-memory of leftmost.</span></div>
<div class="line">    <span class="keyword">auto</span> leftmost_diff_dst_iter_memory</div>
<div class="line">            = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>(leftmost_bwd_prim_desc.diff_dst_iter_desc(), eng);</div>
<div class="line">    <span class="keyword">auto</span> leftmost_diff_dst_iter_c_memory</div>
<div class="line">            = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>(leftmost_bwd_prim_desc.diff_dst_iter_c_desc(), eng);</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> rightmost_diff_src_iter_md</div>
<div class="line">            = leftmost_diff_dst_iter_memory.get_desc().submemory_desc(</div>
<div class="line">                    rightmost_src_iter_dims,</div>
<div class="line">                    {0, 0, 0, 0}); <span class="comment">// l, d, n, c offsets</span></div>
<div class="line">    <span class="keyword">auto</span> rightmost_diff_src_iter_memory = leftmost_diff_dst_iter_memory;</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> rightmost_diff_src_iter_c_md</div>
<div class="line">            = leftmost_diff_dst_iter_c_memory.get_desc().submemory_desc(</div>
<div class="line">                    rightmost_src_iter_c_dims,</div>
<div class="line">                    {0, 0, 0, 0}); <span class="comment">// l, d, n, c offsets</span></div>
<div class="line">    <span class="keyword">auto</span> rightmost_diff_src_iter_c_memory = leftmost_diff_dst_iter_c_memory;</div>
<div class="line"></div>
<div class="line">    <span class="comment">// Backward rightmost primitive descriptor</span></div>
<div class="line">    <a class="code" href="structdnnl_1_1lstm__backward_1_1desc.html">lstm_backward::desc</a> rightmost_layer_bwd_desc(</div>
<div class="line">            <a class="code" href="group__cpp__api__enums.html#ggac7db48f6583aa9903e54c2a39d65438fa195fe59b6f103787a914aead0f3db502">prop_kind::backward</a>, <span class="comment">// aprop_kind</span></div>
<div class="line">            rnn_direction::unidirectional_left2right, <span class="comment">// direction</span></div>
<div class="line">            user_rightmost_src_layer_md, <span class="comment">// src_layer_desc</span></div>
<div class="line">            generic_md(rightmost_src_iter_dims), <span class="comment">// src_iter_desc</span></div>
<div class="line">            generic_md(rightmost_src_iter_c_dims), <span class="comment">// src_iter_c_desc</span></div>
<div class="line">            generic_md(common_weights_layer_dims), <span class="comment">// weights_layer_desc</span></div>
<div class="line">            generic_md(common_weights_iter_dims), <span class="comment">// weights_iter_desc</span></div>
<div class="line">            generic_md(common_bias_dims), <span class="comment">// bias_desc</span></div>
<div class="line">            formatted_md(rightmost_dst_layer_dims, tag::tnc), <span class="comment">// dst_layer_desc</span></div>
<div class="line">            <a class="code" href="structdnnl_1_1memory_1_1desc.html">memory::desc</a>(), <span class="comment">// dst_iter_desc</span></div>
<div class="line">            <a class="code" href="structdnnl_1_1memory_1_1desc.html">memory::desc</a>(), <span class="comment">// dst_iter_c_desc</span></div>
<div class="line">            user_rightmost_diff_src_layer_md, <span class="comment">// diff_src_layer_desc</span></div>
<div class="line">            rightmost_diff_src_iter_md, <span class="comment">// diff_src_iter_desc</span></div>
<div class="line">            rightmost_diff_src_iter_c_md, <span class="comment">// diff_src_iter_c_desc</span></div>
<div class="line">            generic_md(common_weights_layer_dims), <span class="comment">// diff_weights_layer_desc</span></div>
<div class="line">            generic_md(common_weights_iter_dims), <span class="comment">// diff_weights_iter_desc</span></div>
<div class="line">            generic_md(common_bias_dims), <span class="comment">// diff_bias_desc</span></div>
<div class="line">            user_rightmost_diff_dst_layer_md, <span class="comment">// diff_dst_layer_desc</span></div>
<div class="line">            <a class="code" href="structdnnl_1_1memory_1_1desc.html">memory::desc</a>(), <span class="comment">// diff_dst_iter_desc</span></div>
<div class="line">            <a class="code" href="structdnnl_1_1memory_1_1desc.html">memory::desc</a>() <span class="comment">// diff_dst_iter_c_desc</span></div>
<div class="line">    );</div>
<div class="line">    <span class="keyword">auto</span> rightmost_bwd_prim_desc = <a class="code" href="structdnnl_1_1lstm__backward_1_1primitive__desc.html">lstm_backward::primitive_desc</a>(</div>
<div class="line">            rightmost_layer_bwd_desc, eng, rightmost_prim_desc);</div>
<div class="line"></div>
<div class="line">    <span class="comment">//</span></div>
<div class="line">    <span class="comment">// Memory for backward pass</span></div>
<div class="line">    <span class="comment">//</span></div>
<div class="line"></div>
<div class="line">    <span class="comment">// src layer uses the same memory as forward</span></div>
<div class="line">    <span class="keyword">auto</span> leftmost_src_layer_bwd_memory = leftmost_src_layer_memory;</div>
<div class="line">    <span class="keyword">auto</span> rightmost_src_layer_bwd_memory = rightmost_src_layer_memory;</div>
<div class="line"></div>
<div class="line">    <span class="comment">// Memory for weights and biases for backward pass</span></div>
<div class="line">    <span class="comment">// Try to use the same memory between forward and backward, but</span></div>
<div class="line">    <span class="comment">// sometimes reorders are needed.</span></div>
<div class="line">    <span class="keyword">auto</span> common_weights_layer_bwd_memory = common_weights_layer_memory;</div>
<div class="line">    <span class="keywordflow">if</span> (leftmost_bwd_prim_desc.weights_layer_desc()</div>
<div class="line">            != leftmost_prim_desc.weights_layer_desc()) {</div>
<div class="line">        common_weights_layer_bwd_memory</div>
<div class="line">                = memory(leftmost_bwd_prim_desc.weights_layer_desc(), eng);</div>
<div class="line">        reorder(common_weights_layer_memory, common_weights_layer_bwd_memory)</div>
<div class="line">                .execute(s, common_weights_layer_memory,</div>
<div class="line">                        common_weights_layer_bwd_memory);</div>
<div class="line">    }</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> common_weights_iter_bwd_memory = common_weights_iter_memory;</div>
<div class="line">    <span class="keywordflow">if</span> (leftmost_bwd_prim_desc.weights_iter_desc()</div>
<div class="line">            != leftmost_prim_desc.weights_iter_desc()) {</div>
<div class="line">        common_weights_iter_bwd_memory</div>
<div class="line">                = memory(leftmost_bwd_prim_desc.weights_iter_desc(), eng);</div>
<div class="line">        reorder(common_weights_iter_memory, common_weights_iter_bwd_memory)</div>
<div class="line">                .execute(s, common_weights_iter_memory,</div>
<div class="line">                        common_weights_iter_bwd_memory);</div>
<div class="line">    }</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> common_bias_bwd_memory = common_bias_memory;</div>
<div class="line">    <span class="keywordflow">if</span> (leftmost_bwd_prim_desc.bias_desc() != common_bias_memory.get_desc()) {</div>
<div class="line">        common_bias_bwd_memory</div>
<div class="line">                = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>(leftmost_bwd_prim_desc.bias_desc(), eng);</div>
<div class="line">        reorder(common_bias_memory, common_bias_bwd_memory)</div>
<div class="line">                .execute(s, common_bias_memory, common_bias_bwd_memory);</div>
<div class="line">    }</div>
<div class="line"></div>
<div class="line">    <span class="comment">// diff_weights and biases</span></div>
<div class="line">    <span class="keyword">auto</span> common_diff_weights_layer_memory</div>
<div class="line">            = user_common_diff_weights_layer_memory;</div>
<div class="line">    <span class="keyword">auto</span> reorder_common_diff_weights_layer = <span class="keyword">false</span>;</div>
<div class="line">    <span class="keywordflow">if</span> (leftmost_bwd_prim_desc.diff_weights_layer_desc()</div>
<div class="line">            != common_diff_weights_layer_memory.get_desc()) {</div>
<div class="line">        common_diff_weights_layer_memory = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>(</div>
<div class="line">                leftmost_bwd_prim_desc.diff_weights_layer_desc(), eng);</div>
<div class="line">        reorder_common_diff_weights_layer = <span class="keyword">true</span>;</div>
<div class="line">    }</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> common_diff_bias_memory = user_common_diff_bias_memory;</div>
<div class="line">    <span class="keyword">auto</span> reorder_common_diff_bias = <span class="keyword">false</span>;</div>
<div class="line">    <span class="keywordflow">if</span> (leftmost_bwd_prim_desc.diff_bias_desc()</div>
<div class="line">            != common_diff_bias_memory.get_desc()) {</div>
<div class="line">        common_diff_bias_memory</div>
<div class="line">                = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>(leftmost_bwd_prim_desc.diff_bias_desc(), eng);</div>
<div class="line">        reorder_common_diff_bias = <span class="keyword">true</span>;</div>
<div class="line">    }</div>
<div class="line"></div>
<div class="line">    <span class="comment">// dst_layer memory for backward pass</span></div>
<div class="line">    <span class="keyword">auto</span> leftmost_dst_layer_bwd_memory = leftmost_dst_layer_memory;</div>
<div class="line">    <span class="keywordflow">if</span> (leftmost_bwd_prim_desc.dst_layer_desc()</div>
<div class="line">            != leftmost_dst_layer_bwd_memory.get_desc()) {</div>
<div class="line">        leftmost_dst_layer_bwd_memory</div>
<div class="line">                = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>(leftmost_bwd_prim_desc.dst_layer_desc(), eng);</div>
<div class="line">        reorder(leftmost_dst_layer_memory, leftmost_dst_layer_bwd_memory)</div>
<div class="line">                .execute(s, leftmost_dst_layer_memory,</div>
<div class="line">                        leftmost_dst_layer_bwd_memory);</div>
<div class="line">    }</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> rightmost_dst_layer_bwd_memory = rightmost_dst_layer_memory;</div>
<div class="line">    <span class="keywordflow">if</span> (rightmost_bwd_prim_desc.dst_layer_desc()</div>
<div class="line">            != rightmost_dst_layer_bwd_memory.get_desc()) {</div>
<div class="line">        rightmost_dst_layer_bwd_memory</div>
<div class="line">                = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>(rightmost_bwd_prim_desc.dst_layer_desc(), eng);</div>
<div class="line">        reorder(rightmost_dst_layer_memory, rightmost_dst_layer_bwd_memory)</div>
<div class="line">                .execute(s, rightmost_dst_layer_memory,</div>
<div class="line">                        rightmost_dst_layer_bwd_memory);</div>
<div class="line">    }</div>
<div class="line"></div>
<div class="line">    <span class="comment">// Similar to forward, the backward primitives are connected</span></div>
<div class="line">    <span class="comment">// via &quot;iter&quot; parameters.</span></div>
<div class="line">    <span class="keyword">auto</span> common_diff_weights_iter_memory = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>(</div>
<div class="line">            leftmost_bwd_prim_desc.diff_weights_iter_desc(), eng);</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> leftmost_dst_iter_bwd_memory = leftmost_dst_iter_memory;</div>
<div class="line">    <span class="keywordflow">if</span> (leftmost_bwd_prim_desc.dst_iter_desc()</div>
<div class="line">            != leftmost_dst_iter_bwd_memory.get_desc()) {</div>
<div class="line">        leftmost_dst_iter_bwd_memory</div>
<div class="line">                = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>(leftmost_bwd_prim_desc.dst_iter_desc(), eng);</div>
<div class="line">        reorder(leftmost_dst_iter_memory, leftmost_dst_iter_bwd_memory)</div>
<div class="line">                .execute(s, leftmost_dst_iter_memory,</div>
<div class="line">                        leftmost_dst_iter_bwd_memory);</div>
<div class="line">    }</div>
<div class="line"></div>
<div class="line">    <span class="keyword">auto</span> leftmost_dst_iter_c_bwd_memory = leftmost_dst_iter_c_memory;</div>
<div class="line">    <span class="keywordflow">if</span> (leftmost_bwd_prim_desc.dst_iter_c_desc()</div>
<div class="line">            != leftmost_dst_iter_c_bwd_memory.get_desc()) {</div>
<div class="line">        leftmost_dst_iter_c_bwd_memory</div>
<div class="line">                = <a class="code" href="structdnnl_1_1memory.html">dnnl::memory</a>(leftmost_bwd_prim_desc.dst_iter_c_desc(), eng);</div>
<div class="line">        reorder(leftmost_dst_iter_c_memory, leftmost_dst_iter_c_bwd_memory)</div>
<div class="line">                .execute(s, leftmost_dst_iter_c_memory,</div>
<div class="line">                        leftmost_dst_iter_c_bwd_memory);</div>
<div class="line">    }</div>
<div class="line"></div>
<div class="line">    <span class="comment">// Construct the RNN primitive objects for backward</span></div>
<div class="line">    <a class="code" href="structdnnl_1_1lstm__backward.html">lstm_backward</a> rightmost_layer_bwd(rightmost_bwd_prim_desc);</div>
<div class="line">    rightmost_layer_bwd.execute(s,</div>
<div class="line">            {{DNNL_ARG_SRC_LAYER, rightmost_src_layer_bwd_memory},</div>
<div class="line">                    {DNNL_ARG_SRC_ITER, rightmost_src_iter_memory},</div>
<div class="line">                    {DNNL_ARG_SRC_ITER_C, rightmost_src_iter_c_memory},</div>
<div class="line">                    {DNNL_ARG_WEIGHTS_LAYER, common_weights_layer_bwd_memory},</div>
<div class="line">                    {DNNL_ARG_WEIGHTS_ITER, common_weights_iter_bwd_memory},</div>
<div class="line">                    {DNNL_ARG_BIAS, common_bias_bwd_memory},</div>
<div class="line">                    {DNNL_ARG_DST_LAYER, rightmost_dst_layer_bwd_memory},</div>
<div class="line">                    {DNNL_ARG_DIFF_SRC_LAYER, rightmost_diff_src_layer_memory},</div>
<div class="line">                    {DNNL_ARG_DIFF_SRC_ITER, rightmost_diff_src_iter_memory},</div>
<div class="line">                    {DNNL_ARG_DIFF_SRC_ITER_C,</div>
<div class="line">                            rightmost_diff_src_iter_c_memory},</div>
<div class="line">                    {DNNL_ARG_DIFF_WEIGHTS_LAYER,</div>
<div class="line">                            common_diff_weights_layer_memory},</div>
<div class="line">                    {DNNL_ARG_DIFF_WEIGHTS_ITER,</div>
<div class="line">                            common_diff_weights_iter_memory},</div>
<div class="line">                    {DNNL_ARG_DIFF_BIAS, common_diff_bias_memory},</div>
<div class="line">                    {DNNL_ARG_DIFF_DST_LAYER, rightmost_diff_dst_layer_memory},</div>
<div class="line">                    {DNNL_ARG_WORKSPACE, rightmost_workspace_memory}});</div>
<div class="line"></div>
<div class="line">    <a class="code" href="structdnnl_1_1lstm__backward.html">lstm_backward</a> leftmost_layer_bwd(leftmost_bwd_prim_desc);</div>
<div class="line">    leftmost_layer_bwd.execute(s,</div>
<div class="line">            {{DNNL_ARG_SRC_LAYER, leftmost_src_layer_bwd_memory},</div>
<div class="line">                    {DNNL_ARG_WEIGHTS_LAYER, common_weights_layer_bwd_memory},</div>
<div class="line">                    {DNNL_ARG_WEIGHTS_ITER, common_weights_iter_bwd_memory},</div>
<div class="line">                    {DNNL_ARG_BIAS, common_bias_bwd_memory},</div>
<div class="line">                    {DNNL_ARG_DST_LAYER, leftmost_dst_layer_bwd_memory},</div>
<div class="line">                    {DNNL_ARG_DST_ITER, leftmost_dst_iter_bwd_memory},</div>
<div class="line">                    {DNNL_ARG_DST_ITER_C, leftmost_dst_iter_c_bwd_memory},</div>
<div class="line">                    {DNNL_ARG_DIFF_SRC_LAYER, leftmost_diff_src_layer_memory},</div>
<div class="line">                    {DNNL_ARG_DIFF_WEIGHTS_LAYER,</div>
<div class="line">                            common_diff_weights_layer_memory},</div>
<div class="line">                    {DNNL_ARG_DIFF_WEIGHTS_ITER,</div>
<div class="line">                            common_diff_weights_iter_memory},</div>
<div class="line">                    {DNNL_ARG_DIFF_BIAS, common_diff_bias_memory},</div>
<div class="line">                    {DNNL_ARG_DIFF_DST_LAYER, leftmost_diff_dst_layer_memory},</div>
<div class="line">                    {DNNL_ARG_DIFF_DST_ITER, leftmost_diff_dst_iter_memory},</div>
<div class="line">                    {DNNL_ARG_DIFF_DST_ITER_C, leftmost_diff_dst_iter_c_memory},</div>
<div class="line">                    {DNNL_ARG_WORKSPACE, leftmost_workspace_memory}});</div>
<div class="line">    <span class="keywordflow">if</span> (reorder_common_diff_weights_layer) {</div>
<div class="line">        reorder(common_diff_weights_layer_memory,</div>
<div class="line">                user_common_diff_weights_layer_memory)</div>
<div class="line">                .execute(s, common_diff_weights_layer_memory,</div>
<div class="line">                        user_common_diff_weights_layer_memory);</div>
<div class="line">    }</div>
<div class="line"></div>
<div class="line">    <span class="keywordflow">if</span> (reorder_common_diff_bias) {</div>
<div class="line">        reorder(common_diff_bias_memory, user_common_diff_bias_memory)</div>
<div class="line">                .execute(s, common_diff_bias_memory,</div>
<div class="line">                        user_common_diff_bias_memory);</div>
<div class="line">    }</div>
<div class="line"></div>
<div class="line">    <span class="comment">//</span></div>
<div class="line">    <span class="comment">// User updates weights and bias using diffs</span></div>
<div class="line">    <span class="comment">//</span></div>
<div class="line"></div>
<div class="line">    s.wait();</div>
<div class="line">}</div>
<div class="line"></div>
<div class="line"><span class="keywordtype">int</span> main(<span class="keywordtype">int</span> argc, <span class="keywordtype">char</span> **argv) {</div>
<div class="line">    <span class="keywordflow">try</span> {</div>
<div class="line">        simple_net(parse_engine_kind(argc, argv));</div>
<div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;Simple net f32 training example passed!\n&quot;</span>;</div>
<div class="line">    } <span class="keywordflow">catch</span> (<a class="code" href="structdnnl_1_1error.html">error</a> &amp;e) {</div>
<div class="line">        std::cerr &lt;&lt; <span class="stringliteral">&quot;status: &quot;</span> &lt;&lt; e.status &lt;&lt; std::endl;</div>
<div class="line">        std::cerr &lt;&lt; <span class="stringliteral">&quot;message: &quot;</span> &lt;&lt; e.message &lt;&lt; std::endl;</div>
<div class="line">        <span class="keywordflow">return</span> 1;</div>
<div class="line">    }</div>
<div class="line">    <span class="keywordflow">return</span> 0;</div>
<div class="line">}</div>
</div><!-- fragment --> </div></div><!-- contents -->
<div class="footer">
    <div class="footer-wrapper">
        <ul id="footer-links">
            <li><a href="legal_information.html">Legal information</a></li>
        </ul>
    </div>
</div>